---
layout: post
image: /images/visgym.png
venue: "Preprint"
title:  "VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents"
authors: <strong>Zirui Wang*</strong>, Junyi Zhang*, Jiaxin Ge*, Long Lian, Letian Fu, Lisa Dunlap, Ken Goldberg, Xudong Wang, Ion Stoica, David M. Chan, Sewon Min, Joseph E. Gonzalez
date:   2026-01-12 00:00:00 +00:00
website: "https://visgym.github.io/"
arxiv: "https://arxiv.org/abs/2601.16973"
code: "https://github.com/visgym/VIsGym"
categories: research
---
We introduce VisGym, a gymnasium of 17 environments for evaluating and training VLMs. The suite spans symbolic puzzles, real-image understanding, navigation, and manipulation, and provides flexible controls over difficulty, input representation, planning horizon, and feedback.